{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring participant post-test\n",
    "\n",
    "Here is the step-by-step code for scoring participant data generated during Will Decker's honors thesis. It makes use of `scoring_module.py`, a custom built module for scoring data generated this specific project. Despite this, its usability is highly versatile and some functionality can be transferred across paradigms or modified| for different use. \n",
    "\n",
    "**Supplemental information**\n",
    ">There is one task to be scored. This is a 3-alternative forced choice (3AFC) test with 12 trials. This is hardcoded into `scoring_module.score_stats()` (i.e., this function only handles data with 12 trials). The first half of this notebook consists of basic functionality testing a setting up for `scoring_module.py`. The implementation of `scoring_module.py` begins [here](#trying-with-scoring_module-on-single-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buidling and testing functionality of scoring procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scoring_module as sm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "Load in the data and prepare for additional analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "dd = '/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-003_3afc_1.csv'\n",
    "d = pd.read_csv(dd)\n",
    "\n",
    "# determine which order\n",
    "order = []\n",
    "if d['blocks'][5] == 'block1.csv':\n",
    "    order = 1\n",
    "elif d['blocks'][5] == 'block12.csv':\n",
    "    order =2\n",
    "\n",
    "# remove unnecessary columns \n",
    "label = ['example_outer_loop.thisRepN',\n",
    "'example_outer_loop.thisTrialN',\n",
    "'example_outer_loop.thisN',\n",
    "'example_outer_loop.thisIndex',\n",
    "'example_inner_loop.thisRepN',\n",
    "'example_inner_loop.thisTrialN',\n",
    "'example_inner_loop.thisN',\n",
    "'example_inner_loop.thisIndex',\n",
    "'example_shift_loop.thisRepN',\n",
    "'example_shift_loop.thisTrialN',\n",
    "'example_shift_loop.thisN',\n",
    "'example_shift_loop.thisIndex',\n",
    "'trials_loop.thisRepN',\n",
    "'trials_loop.thisTrialN',\n",
    "'trials_loop.thisN',\n",
    "'trials_loop.thisIndex',\n",
    "'transition_loop.thisRepN',\n",
    "'transition_loop.thisTrialN',\n",
    "'transition_loop.thisN',\n",
    "'transition_loop.thisIndex',\n",
    "'blocks_loop.thisRepN',\n",
    "'blocks_loop.thisTrialN',\n",
    "'blocks_loop.thisN',\n",
    "'blocks_loop.thisIndex',\n",
    "'word_loop.thisRepN',\n",
    "'word_loop.thisTrialN',\n",
    "'word_loop.thisN',\n",
    "'word_loop.thisIndex',\n",
    "'replay_msg_loop.thisRepN',\n",
    "'replay_msg_loop.thisTrialN',\n",
    "'replay_msg_loop.thisN',\n",
    "'replay_msg_loop.thisIndex',\n",
    "'instructions1_key.keys',\n",
    "'instructions1_key.rt',\n",
    "'instructions2_key.keys',\n",
    "'instructions2_key.rt',\n",
    "'instructions3_key.keys',\n",
    "'instructions3_key.rt',\n",
    "'instructions4_key.keys',\n",
    "'instructions4_key.rt',\n",
    "'shift1.started',\n",
    "'shift1.stopped',\n",
    "'shift2_2.started',\n",
    "'shift2_2.stopped',\n",
    "'instructions5_key.keys',\n",
    "'instructions5_key.rt',\n",
    "'word_sound.started',\n",
    "'word1_shape.started',\n",
    "'word_sound.stopped',\n",
    "'word1_shape.stopped',\n",
    "'jitter_shape.started',\n",
    "'jitter_shape.stopped',\n",
    "# 'shift2_shape.started',\n",
    "# 'shift2_shape.stopped',\n",
    "'replay_msg_text.started',\n",
    "'response_text.started',\n",
    "'key_resp.started',\n",
    "'replay_msg_text.stopped',\n",
    "'participant',\n",
    "'order',\n",
    "'date',\n",
    "'expName',\n",
    "'psychopyVersion',\n",
    "'frameRate']\n",
    "\n",
    "d = d.drop(columns=label)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score\n",
    "\n",
    "Create answer key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty df for scoring\n",
    "anskey = pd.DataFrame(columns=['correct_key_resp', 'actual_key_resp', 'assign_codes', 'score'])\n",
    "\n",
    "# set answer key based on order set a few chunks earlier\n",
    "answers =  ['z', 'v', 'v',  'z', 'm', 'z', 'z','v', 'm','v', 'v', 'm']\n",
    "if order == 1:\n",
    "    anskey['correct_key_resp'] = answers\n",
    "elif order == 2:\n",
    "    anskey['correct_key_resp'] = answers[::-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine participant answers with answer key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "anskey['actual_key_resp'] = list(d['key_resp.keys'][5:29].dropna())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score individual responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is 0.4166666666666667.\n"
     ]
    }
   ],
   "source": [
    "# assign codes\n",
    "for i in range(12):\n",
    "    if anskey['correct_key_resp'][i] == anskey['actual_key_resp'][i]:\n",
    "        anskey['assign_codes'][i] = 1\n",
    "    else:\n",
    "        anskey['assign_codes'][i] = 0\n",
    "\n",
    "# get score\n",
    "anskey['score'][1] = (sum(anskey['assign_codes']))/12;\n",
    "\n",
    "# output\n",
    "score= anskey['score'][1];\n",
    "print(f'The score is {score}.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate scores into participant database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in database\n",
    "pdb = pd.read_excel('/decker_honors_thesis_paradigm/participant_database.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with `scoring_module()` on single data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_1sampResult(statistic=nan, pvalue=nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/WILLUSB/decker_honors_thesis_paradigm/Honors-Thesis/scoring/scoring_module.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pdb['score'][idx] = score\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import scoring_module as sm\n",
    "\n",
    "# give it some data\n",
    "# d = '/decker_honors_thesis_paradigm/3afc/data/sub-003_3afc_1.csv' # windows\n",
    "d = '/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-003_3afc_1.csv' # mac\n",
    "\n",
    "# clean data to prepare for scoring\n",
    "order, df, subid = sm.clean_3afc(d)\n",
    "\n",
    "# create answer key\n",
    "anskey = sm.create_anskey(order)\n",
    "\n",
    "# append participant responses to answer key for comparison\n",
    "anskey = sm.merge_participant_data(df, anskey)\n",
    "\n",
    "# score the data\n",
    "anskey, score = sm.score(anskey)\n",
    "\n",
    "# put scores into participant database for future use\n",
    "# participant_database = '/decker_honors_thesis_paradigm/participant_database.xlsx' # windows\n",
    "participant_database = '/Volumes/WILLUSB/decker_honors_thesis_paradigm/participant_database.xlsx'\n",
    "pdb_scores = sm.manage_scores(score, participant_database, subid)\n",
    "\n",
    "# statistics\n",
    "m = sm.score_stats(pdb_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing `scoring_module()` classes"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir = '/decker_honors_thesis_paradigm/3afc/data'\n",
    "subids = ['sub-001', 'sub-002']\n",
    "mydir_list = os.listdir(mydir)\n",
    "filename = mydir_list[0].split('/')[-1]\n",
    "filename2 = filename.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "['/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-001_3afc.csv', '/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-002_3afc.csv']\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for id in subids:\n",
    "    found= False\n",
    "    for filename in mydir_list:\n",
    "        filename2 = filename.split('_')[0]\n",
    "        if id == filename2 and filename.endswith('.csv'):\n",
    "            x.append(mydir + filename)\n",
    "            found = True\n",
    "            break\n",
    "        if not found:\n",
    "            print('Subject ID did not match any found files.')\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the previous chunk of code with `FindFiles` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n"
     ]
    }
   ],
   "source": [
    "files2use = sm.FindFiles(path='/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/')\n",
    "subids = ['sub-001', 'sub-002']\n",
    "files2use.parse_file(subids=subids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the extracted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-001_3afc.csv', '/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-002_3afc.csv']\n"
     ]
    }
   ],
   "source": [
    "x = print(files2use.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring in loop with `scoring_module.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "['/decker_honors_thesis_paradigm/3afc/data\\\\sub-002_3afc.csv', '/decker_honors_thesis_paradigm/3afc/data\\\\sub-003_3afc.csv']\n"
     ]
    }
   ],
   "source": [
    "# get files\n",
    "subs = ['sub-002', 'sub-003']\n",
    "get_files = sm.FindFiles(path='/decker_honors_thesis_paradigm/3afc/data')\n",
    "\n",
    "# parse the files pased on desired subject IDs\n",
    "get_files.parse_files(subids=subs)\n",
    "\n",
    "# check to see which files it found\n",
    "print(get_files.files)"
   ]
  },
  {
>>>>>>> 9bb7e18 (major updates)
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "mydir = '/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/'\n",
    "subids = ['sub-001', 'sub-002']\n",
    "mydir_list = os.listdir(mydir)\n",
    "filename = mydir_list[0].split('/')[-1]\n",
    "filename2 = filename.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "Subject ID did not match any found files.\n",
      "['/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-001_3afc.csv', '/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-002_3afc.csv']\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for id in subids:\n",
    "    found= False\n",
    "    for filename in mydir_list:\n",
    "        filename2 = filename.split('_')[0]\n",
    "        if id == filename2 and filename.endswith('.csv'):\n",
    "            x.append(mydir + filename)\n",
    "            found = True\n",
    "            break\n",
    "        if not found:\n",
    "            print('Subject ID did not match any found files.')\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the previous chunk of code with `FindFiles` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n"
     ]
    }
   ],
   "source": [
    "files2use = sm.FindFiles(path='/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/')\n",
    "subids = ['sub-001', 'sub-002']\n",
    "files2use.parse_file(subids=subids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the extracted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-001_3afc.csv', '/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-002_3afc.csv']\n"
     ]
    }
   ],
   "source": [
    "x = print(files2use.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring in loop with `scoring_module.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "['/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-002_3afc.csv']\n",
      "The score is 0.5.\n",
      "Ttest_1sampResult(statistic=3.697849569948664, pvalue=0.03298798261399429)\n"
     ]
    }
   ],
   "source": [
    "# get files\n",
    "subs = ['sub-002']\n",
    "get_files = sm.FindFiles(path='/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/')\n",
    "\n",
    "# parse the files pased on desired subject IDs\n",
    "get_files.parse_files(subids=subs)\n",
    "\n",
    "# check to see which files it found\n",
    "print(get_files.files)\n",
    "\n",
=======
>>>>>>> 9bb7e18 (major updates)
    "# set empty score \n",
    "scores = []\n",
    "\n",
    "# loop over files\n",
    "for i in get_files.files:\n",
    "\n",
    "    # clean data to prepare for scoring\n",
    "    order, df, subid = sm.clean_3afc(d=i)\n",
    "\n",
    "    # create answer key\n",
    "    anskey = sm.create_anskey(order)\n",
    "\n",
    "    # append participant responses to answer key for comparison\n",
    "    anskey = sm.merge_participant_data(df, anskey)\n",
    "\n",
    "    # score the data\n",
    "    anskey, score = sm.score(anskey)\n",
    "\n",
    "    # return score\n",
    "    print(f'The score is {score}.')\n",
    "    scores.append(score)\n",
    "\n",
<<<<<<< HEAD
    "# calculate statistics\n",
    "scores2 =[0.5, 0.77, 0.81] # example scores becuase loop only ran on single data file\n",
    "m = sm.score_stats(scores=scores2)\n",
    "print(m)"
=======
    "# # calculate statistics\n",
    "# scores2 =[0.5, 0.77, 0.81] # example scores becuase loop only ran on single data file\n",
    "# m = sm.score_stats(scores=scores2)\n",
    "# print(m)"
>>>>>>> 9bb7e18 (major updates)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing some additional custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n",
      "Getting more files\n"
=======
     "ename": "AttributeError",
     "evalue": "module 'scoring_module' has no attribute 'FindFiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# get files\u001b[39;00m\n\u001b[0;32m      2\u001b[0m subs \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39msub-001\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msub-002\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m get_files \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39;49mFindFiles(path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39m# parse the files pased on desired subject IDs\u001b[39;00m\n\u001b[0;32m      6\u001b[0m get_files\u001b[39m.\u001b[39mparse_files(subids\u001b[39m=\u001b[39msubs); \n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scoring_module' has no attribute 'FindFiles'"
>>>>>>> 9bb7e18 (major updates)
     ]
    }
   ],
   "source": [
    "# get files\n",
    "subs = ['sub-001', 'sub-002']\n",
    "get_files = sm.FindFiles(path='/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/')\n",
    "\n",
    "# parse the files pased on desired subject IDs\n",
    "get_files.parse_files(subids=subs); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/WILLUSB/decker_honors_thesis_paradigm/3afc/data/sub-002_3afc.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show files found\n",
    "t = get_files.files\n",
    "\n",
    "# remove specific subject from object\n",
    "to_remove = ['sub-001']\n",
    "get_files.rm_subs(to_remove)\n",
    "\n",
    "# print new files object with sub-001 removed\n",
    "get_files.numfiles # number of files\n",
    "get_files.files"
   ]
<<<<<<< HEAD
=======
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loop within module and with new name updates\n",
    "This allows for a cleaner run of the analysis as the source code now does the bulk of the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n",
      "Looking for more files\n"
     ]
    }
   ],
   "source": [
    "# give it some data\n",
    "subs = ['sub-001', 'sub-002', 'sub-004'] # the subject IDs we wish to run \n",
    "get_files = sm.Data(path='/Volumes/WILLUSB//decker_honors_thesis_paradigm/3afc/data/')\n",
    "get_files.parse_files(subids=subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Volumes/WILLUSB//decker_honors_thesis_paradigm/3afc/data/sub-001_structured.csv', '/Volumes/WILLUSB//decker_honors_thesis_paradigm/3afc/data/sub-002_structured.csv', '/Volumes/WILLUSB//decker_honors_thesis_paradigm/3afc/data/sub-004_structured.csv']\n"
     ]
    }
   ],
   "source": [
    "print(get_files.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scoring_module.Data at 0x11071ae00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files.clean_3afc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   structured random\n",
      "0    0.583333    NaN\n",
      "1    0.500000    NaN\n",
      "2    0.500000    NaN\n"
     ]
    }
   ],
   "source": [
    "get_files.score()\n",
    "scores = get_files.scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=6.999999999999998, pvalue=0.009901970590196573)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = sm.Stats(scores=scores)\n",
    "z.compute(test=1, mu=(1/3))\n",
    "\n",
    "z.statistic"
   ]
>>>>>>> 9bb7e18 (major updates)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
